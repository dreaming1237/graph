## [数据同步服务三] 几个重要的问题
上一小节，主要介绍了一些Mysql数据库同步服务的相关概念，本节将会针对数据同步服务中遇到的几个问题，做具体的解释。

## 全量数据同步
![](https://raw.githubusercontent.com/dreaming1237/graph/master/89D0731C-8287-4540-96E7-17DE003A29CF.png)
假如，我们有一个Source     DB，现在里边已经存在大量数据，为了将这些数据同步到另一个DB或者其他渠道，我们应该怎么做呢？

### MysqlDump
- 我们可以借助Mysql的mysqldump工具，将Source DB中的数据dump成一个文件
- 在Slave中导入刚才dump的文件
- 这种方式主要有以下几个缺点：
  - 我们必须shutdown Master,这样就会影响线上的正常服务。
  - 有可能dump出的文件非常大，在Slave上导入的时候会消耗大量的时间
  
### Binlog
- 我们可以通过读取历史的Binlog 日志文件，重放事件，达到最终的数据一致
- 这种方式也有其局限性：
  - 我们其实只关心数据库的最终状态，并不关心中间的执行过程。也就是说一个字段从A->B,B->C,只要我们最终保证数据是C,就可以。然而，借助Binlog就会将整个过程重放一遍，同时也会多次操作索引，导致不必要的变更操作。
  - 更重要的是，为了保证磁盘空间可用，以及读写效率，通常会定期清理Binlog日志，所以我们无法拿到全量的Binlog日志。
  
### Parallel scan
- 另外一种方法，我们可以开启多个线程，并发读取Source DB中的数据，类似于语句

  ```
  select * from table where id > 1000 and id < 2000
  ```
  可以不断的读取数据库中的数据。
- 这种方式的优点就是我们不必依赖全量的Binlog日志，也不必执行大的dump文件，性能完全依赖于我们的系统以及目标的写入能力。但是这种方式，无法对增量实时数据进行一个很好的跟踪，只能不断的轮训是否有新的数据增加。

## 如何保证消息的顺序
通常，数据同步相关的服务会保证消息至少投递一次（at least once)。另外，由于有的时候事件A发生在事件B之前，是有一定的因果关系。例如我们在Source端有一个操作顺序insert->update1->update2→delete，如果在Target端收到delete->update2->update1→insert,那么这条数据将无法被删除。而大多数情况下，为了提升性能，充分利用计算机的资源，我们必须并发处理一些问题，这个时候就需要在有序性和性能中间做一个权衡。下面我们以kafka作为target分别阐述集中不同的情况：

### 无序情况
- 当我们只有一个topic,一个partition,也只有一个consumer,但是存在多个线程来从consumer中读取消息，那么我们是无法保证消息的有序性的。如下
![](https://github.com/dreaming1237/graph/blob/master/AFD65A60-577C-478F-9244-7203EF6A370C.png?raw=true)
  1. Producer按照顺序投递了Message1,Message2,Message3三条消息
  2. 这三条消息被发送到同一个topic下的同一个partition
  3. 只有一个consumer来按顺序消费这三条消息
  4. 在Consumer端，起了三个线程来消费信息，主要是读取消息后，处理并插入到Target DB中
  5. 此时，消息的原始顺序就被打破了
  
- 另一种情况是当我们将消息写入到不同的partition时，不同的consumer从不同的partition消费消息，此时也会丢失消息的原始顺序。
![](https://raw.githubusercontent.com/dreaming1237/graph/master/B9DE8B42-8705-46A7-A819-7BA59D2CC79B.png)
  1. Producer按照顺序投递了Message1,Message2,Message3三条消息
  2. 这三条消息被发送到不同的partition
  3. 不同的consumer消费了不同的partition,分别接收了三条消息
  4. Consumer在写入到target DB的时候，消息失去有序性
  
### 如何保证消息的有序性
- 有时候，我们并不关心消息的顺序，或者我们可以通过重试来达到最终一致性
![](https://raw.githubusercontent.com/dreaming1237/graph/master/B52A9618-1F56-42F3-B607-3AB76F31A3C8.png)
  1. 前三步和上述步骤一致
  2. 当我们执行如下语句
  
    ```
    "update canal_test set lastname='lastname1' where id = 8;" 

    "update canal_test set lastname='lastname2' where id = 8;" 

    "update canal_test set lastname='lastname3' where id = 8;"
    ```
    
    那么Binlog日志将会如下记录：
    
    ```
    ### UPDATE `test`.`canal_test`
    ### WHERE
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='xxx7'
    ###   @4=NULL
    ###   @5=NULL
    ### SET
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='lastname1'
    ###   @4=NULL
    ###   @5=NULL
    
    ### UPDATE `test`.`canal_test`
    ### WHERE
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='lastname1'
    ###   @4=NULL
    ###   @5=NULL
    ### SET
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='lastname2'
    ###   @4=NULL
    ###   @5=NULL
    
    ### UPDATE `test`.`canal_test`
    ### WHERE
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='lastname2'
    ###   @4=NULL
    ###   @5=NULL
    ### SET
    ###   @1=8
    ###   @2='xxx9'
    ###   @3='lastname3'
    ###   @4=NULL
    ###   @5=NULL
    ```
    
  3. 如果第二条消息被先执行，我们可以在target端执行
  
  ```
  "update canal_test set id = 8, fitstname='xxx9', lastname='lastname2', email=null,phone=null 
  where id=8 and firstname='xxx9' and lastname='lastname1' and email=null and phone=null"
  ```
 
  由于第一条消息未被执行，所以lastname1还是"xxx7"，因此这条语句会失败
  
  4. 如果继续执行第三条语句，依然会失败
  5. 只有当我们执行完第一条语句，我们可以依次重试第二条和第三条语句
  
- 有时候，我们可能只想保证某种约束条件下的有序性，例如单表有序，或者基于主键的有序（也就是相同主键的消息，保证顺序，不同主键消息，不保证顺序）：

![](https://raw.githubusercontent.com/dreaming1237/graph/master/AE367C4F-C22B-4A27-BBA6-B6574CAF04A0.png)


  1. Producer向source DB中按照顺序生产三条消息：Message1, Message2, Message3,这三条消息拥有同样的主键，也就是同一条记录的三个变更
  2. 我们可以将这三条消息根据同一主键的原则，发送到同一个partition中
  3. 这三条消息在同一个partition中会保证他们的顺序
  4. 相关的Consumer消费了这三条消息，所以这三条消息在consumer 中是有序的
  5. 基于相同主键在同一缓存队列中的原则，这三条消息被分配到同一个缓存，以及后续会由同一个线程消费，所以我们可以保证消息的有序性
  
- 有时候，我们必须保证全局的顺序行
![](https://raw.githubusercontent.com/dreaming1237/graph/master/BF9CE209-15CC-4CBE-9801-DB0565E2345F.png)
  1. 我们可以通过一个topic,一个partition,一个consumer，单线程来保证消息的有序性
  2. 如果有多个partitions,就无法保证消息的有序性，前边已经说明
  3. 我们能做的就是在系统内部开启多线程压榨计算机性能，但是在从Soure DB读取的时候，以及写到Target的时候，必须保证消息的有序性。

