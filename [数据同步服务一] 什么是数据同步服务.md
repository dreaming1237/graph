# [数据同步服务一] 什么是数据同步服务

在日常开发工作中，有时候会遇到一些需要将数据同步到其他地方的需求。例如不同机房数据库的备份，实时数据到离线数据的拷贝，业务系统之间的数据同步等等场景。有时候我们面临增量数据的同步，有时候我们需要同步全量数据，我将用几篇文章来总结过去半年工作中遇到的相关数据同步的问题和一些想法。

![](https://raw.githubusercontent.com/dreaming1237/graph/master/CF9DF04B-479A-4F43-A62E-603438B8BFFE.png)

如上图，大多数情况下我们需要将数据库，或者一些其他渠道，例如MQ的数据的数据同步到其他数据库或者其他MQ，这个时候数据同步服务就承担了这一责任。
## 使用场景
- Data Bus: 数据总线，将消息同步到kafka，各业务部门注册使用。
- 合并:将数据库分散的表，或者分散的字段，聚合同步到一张表。
- 在线数据修改:数据同步的过程中，可以修改表的列名， 针对特定字段进行加解密。
- 维护索引：如果我们的搜索引擎中的数据来自一些业务系统或者数据库，当数据发声变更的时候，需要同步搜索引擎更新索引。
- 更新缓存:当Redis被用作缓存时，如果数据发生变更，需要同步到Redis做缓存的更新。

当然，我们可以写代码，以十分原始的方式来解决这种问题。例如，我们可以在每个业务发生变更更新数据库的时候，写一段代码同步去更新缓存。但是，这样提高了我们系统维护的成本，如果新来的同事忘记在新增的接口中添加更新缓存的方法，那么就会出现缓存不一致的情况。其次，每次都来写一段大体重复的逻辑，也是让人很头疼的一件事。这个时候，如果能有一个中间件，在背后帮你默默做了这一件事，是不是就会使得数据同步变的更加方便？省去很多重复的读写逻辑，也让业务开发同学更能专注业务的开发，而不用深陷维护数据一致性带来的烦恼。

## Mysql replication 
我的这几篇文章，打算以Mysql数据库为例，来讲解一下我们是如何做Mysql数据库数据到其他数据库以及kafka的数据同步。要明白这个问题，首先我们应该回顾一下Mysql数据库复制协议。
- https://dev.mysql.com/doc/refman/5.6/en/replication-configuration.html
### Master & Slave
![](https://raw.githubusercontent.com/dreaming1237/graph/master/275B1D94-595A-4304-8DD8-CB6BED023598.png)

我们知道，Mysql在工作的时候，通常为了避免数据的丢失，以及缓解读写压力，都会配置成一台主Master和多台从Slave的模式。通常我们会将写的操作全部执行在Master上，然后再同步到Slave中。他们的工作模式就主要尊徐以下几个步骤：
- Master 在接到新的写请求的时候，会同步在Master本地写下binlog日志，用作故障恢复和数据同步。
- Slave 会从Master 读取Binlog日志，然后写入Slave本地的Relay log。
- 随后，Slave会重放Relay log中的事件，这样Slave中的数据就会跟Master保持一致。这里有个小插曲，当slave重放Relay log中的日志的时候，是否要在Slave本地写Binlog 日志，取决于 log-slave-updates这个参数在配置Slave是否被打开。

这样，我们就了解了Mysql 数据库Master和 Slave之间的数据同步问题。我们可以思考另一个问题，如果我们启动一个进程，将自己伪装成Slave，会发生什么呢？
![](https://raw.githubusercontent.com/dreaming1237/graph/master/0CA6FC1D-72D8-4B32-8F7C-AB2B3DD90A43.png)

不难发现，如果我们依照以下步骤：
- 启动一个进程，向Master打招呼，假装自己是一个合法的Slave
- 向Master发送请求，我们要DUMP相应的binlog 日志
- 在我们自己的进程中解析，重组binlog日志，再讲日志发送到目的地

这样，当Mysql数据库接收到一个写入请求的时候，在我们的目的地（Mysql，kafka, 或者其他渠道）就会准实时收到一条相应的变更。至此，整个系统的大体的工作思路，我们就梳理清楚了，但是依然有很多细节等着我们去解决。